{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:13:09.971923700Z",
     "start_time": "2024-03-19T16:13:09.930249700Z"
    }
   },
   "id": "7845eca57cd1fdbd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Extraction des données des datasets d'HuggingFace</h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6a7def9afba208a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Fonction pour récupérer le dataset card d'un dataset\n",
    "def get_dataset_card(model_name):\n",
    "    model_card_url = f\"https://huggingface.co/datasets/{model_name}/blob/main/README.md\"\n",
    "    response = requests.get(model_card_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:13:09.987993600Z",
     "start_time": "2024-03-19T16:13:09.938132500Z"
    }
   },
   "id": "1846ce3930121f86"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Fonction pour récupérer les données de tous les datasets sur Hugging Face\n",
    "# Les données récupérées sont les métadonnées des datasets et leur dataset card respectif\n",
    "# retourne une liste de dictionnaires (un dictionnaire représente un dataset)\n",
    "def get_datasets_data():\n",
    "    datasets_json = []\n",
    "    \n",
    "    try:\n",
    "        response = session.get(\n",
    "            \"https://huggingface.co/api/datasets\",\n",
    "            params={\"full\": \"True\"},\n",
    "            stream=False\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # On récupére les métadonnées de tous les datasets\n",
    "        datasets = response.json()\n",
    "        \n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = []\n",
    "            for dataset in datasets:\n",
    "                # On enlève les données inutiles pour réduire la taille du fichier json\n",
    "                if \"cardData\" in dataset and \"configs\" in dataset[\"cardData\"]:\n",
    "                    dataset[\"cardData\"].pop(\"configs\")\n",
    "                if \"siblings\" in dataset:\n",
    "                    dataset.pop(\"siblings\")\n",
    "                if \"tags\" in dataset:\n",
    "                    dataset.pop(\"tags\")\n",
    "                \n",
    "                # On récupère les datasets cards en parallèle pour gagner du temps\n",
    "                dataset_name = dataset['id']\n",
    "                future = executor.submit(get_dataset_card, dataset_name)\n",
    "                futures.append((dataset, future))\n",
    "            \n",
    "            # Pour chaque dataset, on lui associe son dataset card\n",
    "            for dataset, future in tqdm(futures):\n",
    "                dataset_card = future.result()\n",
    "                if dataset_card:\n",
    "                    dataset[\"dataset_card\"] = dataset_card\n",
    "                    datasets_json.append(dataset)\n",
    "        \n",
    "        return datasets_json\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching datasets: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing datasets: {e}\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:13:15.004383Z",
     "start_time": "2024-03-19T16:13:14.997243900Z"
    }
   },
   "id": "df31114f67a8552e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [09:56<00:00, 16.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Création d'une session pour les requêtes HTTP\n",
    "session = requests.Session()\n",
    "session.headers.update({\"Authorization\": \"Bearer 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\"})\n",
    "\n",
    "# Récupération des données des datasets\n",
    "datasets = get_datasets_data()\n",
    "\n",
    "# Création d'un fichier json avec les données des datasets\n",
    "with open(\"datasets.json\", \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(datasets, f, ensure_ascii=False, indent=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T17:05:45.375828Z",
     "start_time": "2024-03-19T16:55:43.816825900Z"
    }
   },
   "id": "836ef298cdf1c5df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Extraction des données des dataset cards</h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70223029c180783a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def get_description_from_card(model_card):\n",
    "    description_keywords =\\\n",
    "    [\"Description\", \"description\", \"Summary\", \"summary\", \"Detail\", \"detail\", \"Dataset\", \"dataset\"]\n",
    "    \n",
    "    description = \"\"\n",
    "    lines = model_card.split(\"\\n\")\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        if lines[i].startswith(\"#\"):\n",
    "            for description_keyword in description_keywords:\n",
    "                if description_keyword in lines[i]:\n",
    "                    # On récupère la description du dataset\n",
    "                    i+=1\n",
    "                    while i < len(lines) and not lines[i].startswith(\"#\"):\n",
    "                        description = description + lines[i]\n",
    "                        i+=1\n",
    "                    return description\n",
    "    return None "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T17:59:07.116376700Z",
     "start_time": "2024-03-19T17:59:07.107213900Z"
    }
   },
   "id": "57daac6749559033"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 836/836 [00:00<00:00, 3075.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "836\n",
      "Pourcentage de dataset cards avec description: 0.12%\n",
      "[{'description': '<!-- HTML_TAG_END --></div></div></section></div></main>\\t</div>\\t\\t<script>\\t\\t\\timport(\"/front/build/kube-9a810cf/index.js\");\\t\\t\\twindow.moonSha = \"kube-9a810cf/\";\\t\\t\\twindow.hubConfig = JSON.parse(`{\"features\":{\"signupDisabled\":false},\"sshGitUrl\":\"git@hf.co\",\"moonHttpUrl\":\"https://huggingface.co\",\"captchaApiKey\":\"bd5f2066-93dc-4bdd-a64b-a24646ca3859\",\"captchaDisabledOnSignup\":true,\"datasetsServerPublicUrl\":\"https://datasets-server.huggingface.co\",\"stripePublicKey\":\"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc\",\"environment\":\"production\",\"userAgent\":\"HuggingFace (production)\"}`);\\t\\t</script>\\t\\t<!-- Stripe -->\\t\\t<script>\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\t\\t\\t\\tconst script = document.createElement(\"script\");\\t\\t\\t\\tscript.src = \"https://js.stripe.com/v3/\";\\t\\t\\t\\tscript.async = true;\\t\\t\\t\\tdocument.head.appendChild(script);\\t\\t\\t}\\t\\t</script>\\t\\t<!-- Google analytics v4 -->\\t\\t<script>\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\t\\t\\t\\tconst script = document.createElement(\"script\");\\t\\t\\t\\tscript.src = \"https://www.googletagmanager.com/gtag/js?id=G-8Q63TH4CSL\";\\t\\t\\t\\tscript.async = true;\\t\\t\\t\\tdocument.head.appendChild(script);\\t\\t\\t\\twindow.dataLayer = window.dataLayer || [];\\t\\t\\t\\tfunction gtag() {\\t\\t\\t\\t\\tif (window.dataLayer !== undefined) {\\t\\t\\t\\t\\t\\twindow.dataLayer.push(arguments);\\t\\t\\t\\t\\t}\\t\\t\\t\\t}\\t\\t\\t\\tgtag(\"js\", new Date());\\t\\t\\t\\tgtag(\"config\", \"G-8Q63TH4CSL\", { page_path: \"/datasets/Cropinky/rap_lyrics_english/blob/main/README.md\" });\\t\\t\\t\\t/// ^ See https://developers.google.com/analytics/devguides/collection/gtagjs/pages\\t\\t\\t\\tgtag(\"consent\", \"default\", { ad_storage: \"denied\", analytics_storage: \"denied\" });\\t\\t\\t\\t/// ^ See https://developers.google.com/tag-platform/gtagjs/reference#consent\\t\\t\\t\\t/// TODO: ask the user for their consent and update this with gtag(\\'consent\\', \\'update\\')\\t\\t\\t}\\t\\t</script>\\t</body></html>', 'id': 'Cropinky/rap_lyrics_english'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parcourir le fichier json des datasets pour récupérer les dataset cards\n",
    "with open(\"datasets.json\", \"r\", encoding=\"utf8\") as f:\n",
    "    datasets = json.load(f)\n",
    "\n",
    "descriptions = []\n",
    "nb_datasets = len(datasets)\n",
    "nb_descriptions_found = 0\n",
    "# Récupération des descriptions des dataset cards\n",
    "for dataset in tqdm(datasets):\n",
    "    if \"dataset_card\" in dataset:\n",
    "        dataset_card = dataset[\"dataset_card\"]\n",
    "        description = get_description_from_card(dataset_card)\n",
    "        if description:\n",
    "            descriptions.append({\"description\":description, \"id\":dataset[\"id\"]})\n",
    "            nb_descriptions_found += 1\n",
    "\n",
    "print(nb_descriptions_found)\n",
    "print(nb_datasets)\n",
    "print(f\"Pourcentage de dataset cards avec description: {(nb_descriptions_found/nb_datasets)*100:.2f}%\")\n",
    "print(descriptions[:20])\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T18:02:05.000007400Z",
     "start_time": "2024-03-19T18:02:03.008406200Z"
    }
   },
   "id": "ed19c55c6a86bcd3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
